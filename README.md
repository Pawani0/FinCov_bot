# FinCov-Backend

This project is an AI-powered Voice Assistant application designed to provide natural voice-based interaction between users and a language model. The backend of this application is developed using FastAPI, with a strong focus on real-time communication, audio processing, and retrieval-augmented generation (RAG).

## ğŸ‘¥ Contributors:
ğŸ‘¨â€ğŸ’» Arsh Ahmad - (Endpoints and FastAPI integration) <br>
ğŸ‘¨â€ğŸ’» Rishabh Pawani - (Classification engine RAG and NLP) <br>
ğŸ‘¨â€ğŸ’» Tilak Gupta - (Vector storage and Embeddings) <br>
ğŸ‘¨â€ğŸ’» Sumit Mewada - (Speech-To-Text and Text-To-Speech) <br>


## ğŸ› ï¸ Setup Instructions
### ğŸ”§ Backend Setup
```
1. Create a virtual environment.
    python -m venv venv 
    # On Windows: .\venv\Scripts\activate
2. Create the given file structure.
3. Copy source code files according to the file structure.
4. Now install all the dependencies in terminal using
    pip install -r requirements.txt
```
### ğŸ“ File Structure
```
FinCov-Backend
 â”œâ”€â”€ query_engine
 â”‚      â”œâ”€â”€ docs
 â”‚      â”‚    â”œâ”€â”€ banking.txt
 â”‚      â”‚    â”œâ”€â”€ insurance.txt
 â”‚      â”‚    â”œâ”€â”€ investment.txt
 â”‚      â”‚    â”œâ”€â”€ loan.txt
 â”‚      â”‚    â””â”€â”€ tax.txt
 â”‚      â”œâ”€â”€ faiss_index
 â”‚      â”‚    â”œâ”€â”€ banking
 â”‚      â”‚    â”‚    â”œâ”€â”€ index.faiss
 â”‚      â”‚    â”‚    â””â”€â”€ index.pkl
 â”‚      â”‚    â”œâ”€â”€ insurance
 â”‚      â”‚    â”‚    â”œâ”€â”€ index.faiss
 â”‚      â”‚    â”‚    â””â”€â”€ index.pkl 
 â”‚      â”‚    â”œâ”€â”€ investment
 â”‚      â”‚    â”‚    â”œâ”€â”€ index.faiss
 â”‚      â”‚    â”‚    â””â”€â”€ index.pkl
 â”‚      â”‚    â”œâ”€â”€ loan
 â”‚      â”‚    â”‚    â”œâ”€â”€ index.faiss
 â”‚      â”‚    â”‚    â””â”€â”€ index.pkl
 â”‚      â”‚    â””â”€â”€ tax
 â”‚      â”‚         â”œâ”€â”€ index.faiss
 â”‚      â”‚         â””â”€â”€ index.pkl
 â”‚      â”œâ”€â”€ classifier_engine.py
 â”‚      â”œâ”€â”€ intents.json 
 â”‚      â”œâ”€â”€ rag_pipeline.py 
 â”‚      â””â”€â”€ vector_indexing.py
 â”œâ”€â”€ utils
 â”‚      â”œâ”€â”€ auth_routes.py
 â”‚      â”œâ”€â”€ chat_storage.py
 â”‚      â”œâ”€â”€ tts.py
 â”‚      â””â”€â”€ twilio_verify.py
 â”œâ”€â”€ main.py
 â”œâ”€â”€ .env
 â”œâ”€â”€ README.md
 â””â”€â”€ requirements.txt
```

### ğŸ” Update .env with your keys: 
```
# Google Gemini API Key (required)
GOOGLE_API_KEY="YOUR_GOOGLE_API_KEY"

# Text-To-Speech Backend (optional)
# edge (default) | unmute
TTS_BACKEND="edge"

# UNMUTE (Kyutai) WebSocket server URL (required if TTS_BACKEND=unmute)
# Example: ws://localhost:7331/tts
UNMUTE_WS_URL="ws://localhost:7331/tts"

# Twilio API IDs (for OTP verification)
TWILIO_ACCOUNT_SID="YOUR_ACCOUNT_SID"
TWILIO_AUTH_TOKEN="YOUR_AUTH_TOKEN"
TWILIO_VERIFY_SID="YOUR_VERIFY_SID"

Note: Create this .env file and add your keys above. Set TTS_BACKEND to "unmute" only if you have an UNMUTE-compatible server running.
```
# **FinCov-Ai_modules**  
- ## Domain Classifier Engine
  #### To classify domain follow the steps :
  1. Import `classify_domain` from `query_engine.classifier_engine`.
     ```python
     from query_engine.classifier_engine import classify_domain
     ```
  2. Pass User query in the function.
     ```python
     classify_domain(querry)
     ```
- ## Intent Classifier Engine
  #### To find out the intent of query follow the steps :
  1. Import `classify_intent` from `query_engine.classifier_engine`.
     ```python
     from query_engine.classifier_engine import classify_intent
     ```
  2. Pass User query and domain to the function.
     ```python
     classify_intent(query, domain)
     ```
- ## Retrieval-Augmented Generation(RAG)
  #### For asking query using RAG follow the steps :
  1. Import `ask` and `load_all_vectorstores` from `query_engine.rag_pipeline`.
     ```python
     from query_engine.rag_pipeline import ask, load_all_vectorstores
     ```
  2. Load all vectorstores in the starting.
     ```python
     vectorstores = load_all_vectorstores()
     ```
  3. Now, pass Session ID, User query and vectorstore to the function.
     ```python
     ask(SID, query, vectorstores[domain])
     ```
     Here, `SID` is Session ID in string format.
           `query` is the user query.
           `vectorstores[domain]` is the vectorstore of particular domain.
     
     Note: Handle domain and intent correctly as they can return `None`.

- ## Text-To-Speech (TTS)
  The server supports streaming audio responses over WebSocket using a pluggable TTS backend.
  - Default backend: `edge_tts`
  - Low-latency backend: `UNMUTE (Kyutai)` via WebSocket

  #### Configure
  1. Set `TTS_BACKEND` in `.env`:
     - `edge` (default)
     - `unmute`
  2. If using `unmute`, set `UNMUTE_WS_URL` (e.g., `ws://localhost:7331/tts`).

  #### Notes
  - `edge_tts` streams audio after receiving full text.
  - `UNMUTE` aims for near real-time streaming as text is generated. You must run an UNMUTE-compatible WebSocket server separately.

- ## MongoDB utility
  #### For saving the conversation on database.
  1. Make sure that You save `MONGO_URI` in .env file.
     `MONGO_URI = "Your_URI_from_mongo_db"`
  2. Import `dump_session_to_mongo` and `store_message` from `utils.chat_storage`.
     ```python
     from utils.chat_storage import dump_session_to_mongo, store_message
     ```
  3. Use `store_message()` to store the pair of messages between the human and the bot in a temporary dictionary.
     ```python
     store_message(session_id, query, response, domain, intent)
     ```
     Pass all the parameters: session id, query, response, domain and intent.
  4. Now just pass the `SID` in `dump_session_to_mongo()`.
     ```python
     dump_session_to_mongo(SID)
     ```
